5 Mistakes C/C++ Devs make writing Go
A newbie's journey into Go

Aug 29 2018

Nyah Check
Software Engineer, Altitude Networks
nyah@altitudenetworks.com
https://github.com/Ch3ck
@nyah_check


* Why am I here?

- Wrote C/C++ for close to 5 years before Go.

- Brought bad C style code in Go and had a lot of issues


* What you'll learn...

- Learn from my mistakes

- Avoid some common pitfalls newbies face writing Go


* Agenda

I classified the 5 mistakes under 4 topics:

- Escape Analysis
- Memory leaks
- Goroutine leaks
- Error handling

I'll be open to questions at the end of the presention


* One more thing ...

This is a discussion

If you don't understand something, or think what I'm saying is incorrect, please ask.

* Escape Analysis

* Mistake 1: New doesn't mean heap && var doesn't mean stack

An early mistake was to minimize _escape_analysis_ and it's possible implications my program's performances


Consider the following _C++_ code
.code 01-new-doesnt-mean-heap/examples/heap.cpp /START OMIT/,/END OMIT/

* Wrong assumptions..

- In C++, we know *new* allocates to the value stored at *a* on the heap.

- In Go, we don't really know for sure. 
- May be the *new* keyword was stolen from C++ as a result might likely be allocated on the heap?

- Given my C++ bias, I thought minimizing it's use will reduce _heap_ allocation.


* Let's look at some code...

.code 01-new-doesnt-mean-heap/examples/heap.go /START OMIT/,/END OMIT/

* Question

Where do we think the *vv* variable will be allocated? *stack* or *heap*?

* Let's look at the compiler escape decisions output

    $ go run -gcflags -m main.go
    # command-line-arguments
    ./main.go:6:6: can inline newIntStack
    ./main.go:12:39: inlining call to newIntStack
    ./main.go:7:11: new(int) escapes to heap
    ./main.go:12:27: *(*int)(~r0) escapes to heap
    ./main.go:12:39: main new(int) does not escape         <--- Surprise!!!
    ./main.go:12:26: main ... argument does not escape
    0

* Let's take a look at another example

    package main

    import "fmt"

    func main() {
        x := "GOPHERCON-2018"
        fmt.Println(x)
    }

* Where will x be allocated?

Stack or Heap?

* Let's find out...

    ➜  examples git:(master) ✗ go run -gcflags -m main.go
    # command-line-arguments
    ./main.go:15:13: x escapes to heap        <---- STRANGE THINGS!
    ./main.go:15:13: main ... argument does not escape
    GOPHERCON-2018
    ➜  examples git:(master) ✗


It's surprising to see *x* which not called outside may is allocated on the heap instead.

* Why?

I’ll pass the -m option multiple times to make the output more verbose:

    ➜  examples git:(master) ✗ go run -gcflags '-m -m'  main.go
    # command-line-arguments
    ./main.go:13:6: cannot inline main: non-leaf function
    ./main.go:15:13: x escapes to heap
    ./main.go:15:13:        from ... argument (arg to ...) at ./main.go:15:13
    ./main.go:15:13:        from *(... argument) (indirection) at ./main.go:15:13
    ./main.go:15:13:        from ... argument (passed to call[argument content escapes]) at ./main.go:15:13
    ...                                          // <-- X is called by a funtion above which escapes! -->
    ./main.go:15:13: main ... argument does not escape
    GOPHERCON-2018
    ➜  examples git:(master) ✗

* What happened?

So looking at L15:13

- x is passed to a function argument which `escapes`
- So x is heap allocated instead.

This is very confusing/counterintuitive to a C/C++ developer, yet this is how Go works.


* Lessons

- Escape analysis is very important in writing more performant Go programs, yet there's no language specification on this.
- Some of the compiler's escape analysis decisions are counterintuitive, yet trial and error is the only way to know
- Do not make assumptions, rather do static analysis on the code and make informed decisions.


* Escape Analysis guidelines

- Functions calling other functions
- references assigned to struct members
- slices and maps
- pointers to variables

* Conclusion
"If a reference to a variable is returned from a function where it’s declared, it ‘escapes’ and is heap allocated instead"
.caption

* Memory Leaks

* Mistake 2: Do not defer in an infinite Loop

The *defer* statement is used to clean up resources after you open up a resource(e.g. file, connection etc)

So an idiomatic way will be:

    fp, err := os.Open("path/to/file.text")
    if err != nil {
        //handle error gracefully
    }
    defer fp.Close()

This snippet is guaranteed to work even if cases where there’s a panic and it’s *standard* Go practice. 

* So what's the problem?

In very large files where resources cannot be tracked and freed properly, this becomes a problem.

Consider a file monitoring program in *C* where:
- check a database for changes to files
- perform some operation(logging, send requests etc)

* Something like this might work
.code 02-do-not-defer-in-infinite-loop/examples/file.c /START OMIT/,/END OMIT/
This will be sure to open and close up the files once the operations are done.

* However in Go
.code 02-do-not-defer-in-infinite-loop/examples/main.go /START OMIT/,/END OMIT/

*Problems:*
- Deferred code never executes since the function has not returned
- So memory clean up never happens and it’s use keeps piling up
- Files will never be closed, therefore causing loss of data due to lack of flush.


* How do I fix this?

- Spin up a goroutine for each file monitoring
- This ensures everything is bound to the context
- Hence files are opened and closed

* Solution

.code 02-do-not-defer-in-infinite-loop/examples/main.go /START FIX/,/END FIX/

* Lessons learned

- Since defer is tied to the new function context, we are sure it's executed and memory is flushed when files close
- When defer executes we are certain our goroutine finished execution
- Defer doesn not execute until the function returns, so no memory leaks result

* Conclusion

"A *defer* statement invokes a function whose execution is deferred to the moment the surrounding function returns"
.caption


* Mistake 3: Keeping pointers in an accessible(although not visible) part of a slice

- Prior to Go 1.2 there was a memory safety issue with slices, where you could literally access regions in memory you're not legally permitted to:
- This would create problems where you'll unitentionally rewrite regions of memory and will increase your pain.

* Let's use an example.
Consider the slice:

	a := []*int{new(int), new(int)}
	a = a[:1]
	fmt.Println(a) // [&0]

	// second element is not garbage collected, because it's *still* accessible
	a = a[:2] //[&0] // <-- Illegal memory access
	fmt.Println(a)


Our output will be:

    ➜  examples git:(master) ✗ go run main.go
    [0xc420016090 0xc420016098]
    [0xc420016090]
    [0xc420016090 0xc420016098]


* What are some of the problems?

- This can cause problems later on where you can write data to parts of the slice you shouldn’t have access to
- Memory will be garbage collected as wrongly assumed.
- If you can access certain parts of memory you don’t legally have access to, it may be a source for exploits

* How do you solve this then?

Go 1.2++ added 3-Index-Slice  operation

- This enables you to specify the cap during slicing.

- The restricted slice capacity provides a level of protection to the underlying array and gives us more control over append operations


* How do we use it then

Rewriting our code gives

    a := []*int{new(int), new(int)}
    a = a[:1:1] // THREE INDEX SLICE OPERATION
    fmt.Println(a) // [&0]

    // second element is garbage collected, and can no longer be accessible
    a = a[:2]
    fmt.Println(a)

* Our output becomes ...

    ➜  examples git:(master) ✗ go run main.go
    [0xc420016090 0xc420016098]
    [0xc420016090]
    panic: runtime error: slice bounds out of range

    goroutine 1 [running]:
    main.main()
        /Users/nyahcheck/go/src/github.com/Ch3ck/5-mistakes-c-cpp-devs-make-writing-go/03-pointer-in-non-visible-slice-portion/examples/main.go:27 +0x1ae
    exit status 2

Our slice cap was set to 1, we can't access regions of memoery we don't have permissions to, rightly creating a panic.

* Lesson

Three index slicing creates a memory safety feature for your Go programs which pervents certain parts of memory to accesses/modified intentionally or otherwise.



* Goroutine leaks

* Mistake 4: Error handling with channels where # channels < # goroutines


- C/C++ has libraries for multi-threaded programming,
- Concurrency in Goconcurrency in Go materializes itself in the form of goroutines and channels.
- How do you avoid goroutine leakages
 One of the issues programmers will deal with is how to void their leakages.

Causes:

- Infinite loops
- Blocked I/O channels

When these occur more cpu/memory resources are used than actually needed. Leading to frequent program crashes

* Let's consider the following example

- We'll look at the issue
- Fix it and discuss go tools available to handle these kinds of issues

.code 04-error-handling-with-channels/examples/main.go

* What does our code do?

This program spins up two goroutines and runs some internal processes and writes the results to a channel

Our output here is:
    ➜  examples git:(master) ✗ go run main.go
    2018/08/28 14:09:54 profile: trace enabled, /var/folders/s7/s4fj1d3j07b5wqy3jw_lpwj00000gn/T/profile307450157/trace.out
    done wth a
    something went wrong with a
    done with b
    done wth a
    something went wrong with a
    done with b
    done with b
    something went wrong with b
    done wth a
    done with b
    something went wrong with b
    done wth a
    done wth a
    something went wrong with a
    done with b
    done wth a
    something went wrong with a
    done with b
    done with b
    something went wrong with b
    done wth a
    done wth a
    something went wrong with a
    done with b
    done with b
    ...

Let's look at the memory build up

    Processes: 481 total, 2 running, 479 sleeping, 3067 threads                                                                                                                    14:22:36
    Load Avg: 2.10, 2.16, 2.20  CPU usage: 2.95% user, 2.36% sys, 94.67% idle  SharedLibs: 157M resident, 40M data, 5464K linkedit.
    MemRegions: 179430 total, 5220M resident, 119M private, 2881M shared. PhysMem: 16G used (3359M wired), 150M unused.
    VM: 7554G vsize, 1111M framework vsize, 3678046(0) swapins, 4327421(0) swapouts. Networks: packets: 14686827/9918M in, 4519629/711M out. Disks: 2386524/45G read, 2410064/54G written.

    PID    COMMAND      %CPU      TIME     #TH    #WQ   #PORT MEM    PURG   CMPRS  PGRP  PPID  STATE    BOOSTS           %CPU_ME %CPU_OTHRS UID  FAULTS    COW     MSGSENT    MSGRECV
    39491  main         0.6       00:00.30 10     0     32    1404K+ 0B     0B     39477 39477 sleeping *0[1]            0.00000 0.00000    501  667+      11      22         11
    39477  go           0.0       00:00.22 16     0     57    9212K  0B     0B     39477 8036  sleeping *0[1]            0.00000 0.00000    501  6854      1531    55         27
    39465  quicklookd   0.0       00:00.14 4      1     85    5060K  32K    0B     39465 1     sleeping  0[0]            0.00000 0.00000    501  4657      258     288        79


* What are the problems with the code
- More go routines than channels are present to write to this function
- When one routine writes to the channel, the program exits and the other goroutine is lost, building up memory use as a results
- that region of memory is not garbage collected

* How do we fix this?

We simply increase the number of channels to 2,
This makes it possible for the two goroutines to pass their results to the calling program.
    ...
    func doSomethingTwice() error {
        // without the 2  goroutines this will leak a goroutine
        //errc := make(chan error, 1) // ISSUE OCCURS HERE
        errc := make(chan error, 2) // FIX TO ISSUE
        go func() {
            defer fmt.Println("done wth a")
            errc <- doSomething("a")
        }()
        go func() {
            defer fmt.Println("done with b")
            errc <- doSomething("b")
        }()
        err := <-errc
        return err
    }
    ...

Our output here becomes

    ➜  examples git:(master) ✗ go run main.go
    2018/08/28 14:29:10 profile: trace enabled, /var/folders/s7/s4fj1d3j07b5wqy3jw_lpwj00000gn/T/profile870826243/trace.out
    done with b
    something went wrong with b
    done wth a
    done wth a
    something went wrong with a
    done with b
    done wth a
    something went wrong with a
    done with b
    done wth a
    something went wrong with a
    done with b
    done wth a

Our memory build up is:

    Processes: 480 total, 2 running, 478 sleeping, 3066 threads                                                                                                                    14:31:45
    Load Avg: 1.79, 2.17, 2.19  CPU usage: 2.70% user, 3.41% sys, 93.87% idle  SharedLibs: 159M resident, 40M data, 5556K linkedit.
    MemRegions: 211071 total, 5727M resident, 103M private, 2878M shared. PhysMem: 16G used (3397M wired), 403M unused.
    VM: 7551G vsize, 1112M framework vsize, 3678685(0) swapins, 4327421(0) swapouts. Networks: packets: 14689235/9919M in, 4522309/711M out. Disks: 2395186/45G read, 2417927/54G written.

    PID    COMMAND      %CPU TIME     #TH   #WQ  #PORT MEM    PURG   CMPRS  PGRP  PPID  STATE    BOOSTS          %CPU_ME %CPU_OTHRS UID  FAULTS    COW     MSGSENT    MSGRECV    SYSBSD
    39844  top          4.8  00:02.74 1/1   0    23    5880K  0B     0B     39844 15534 running  *0[1]           0.00000 0.00000    0    18318+    110     928405+    464178+    66200+
    39835  main         0.6  00:00.30 11    0    35    1396K+ 0B     0B     39821 39821 sleeping *0[1]           0.00000 0.00000    501  667+      11      24         12         5386+
    39821  go           0.0  00:00.18 15    0    54    9272K  0B     0B     39821 8036  sleeping *0[1]           0.00000 0.00000    501  7075      1500    53         26         12111
    39813  quicklookd   0.0  00:00.08 4     1    85    5020K  32K    0B     39813 1     sleeping  0[0]           0.00000 0.00000    501  4617      258     288        79         2292

*Lessons

Goroutine leaks are very common in Go development especially for those without a concurrency programming background. 
However there are some best practices you can follow to avoid some of these errors:

- Using the context package to terminate or timeout goroutines which may otherwise run indefinitely
- Using a done signal or timeout channel can help in terminating a running goroutine preventing leaks
- Profiling the code, Stack trace instrumentation and adding benchmarks can go a long way in finding these leaks
- There are some third party libraries for instrumentation which can be applied:  opencensus, go-torch, goes, leaktest, etc



[[../04-error-handling-with-channels/error-handling-with-channels.slide][Avoiding  goroutine leaks]]

* Error handling
* Mistake 5: Errors are not just strings, but much more



* Discussion


Any questions?


* Conclusion


- *Understand* Escape analysis by looking at the compiler decisions, do not make *reasonable guesses*.


- *Defer* executes only when the function returns. Using it in a infinite loop is a *code smell*.


- Three Index_slices adds a memory *safety* utility in Go, use it.

* Conclusion (cont.)

- *Profile* your Go code to identify bottlenecks early on, it's a good practice.

- Errors in Go are not just strings, but much more.

- Wrap errors to preserve context and handle them gracefully.


* There are many more errors C/C++ devs make

Just remember ...

- Go is not C/C++

- "Programming in Go is like being young again (but more productive!)."
.caption